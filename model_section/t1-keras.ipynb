{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ef1066-d2bc-46c8-9058-6686360151d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO\n",
    "- [ ] <strike>Treinar um modelo, gerar novos dados apenas com volume e vazão diferentes, ver o desempenho</strike>\n",
    "- [ ] <strike>Diferentes situações:</strike>\n",
    "    - [x] reação inversa\n",
    "    - [x] adiabática\n",
    "- [x] <strike> Ver quanto tempo demora pra atingir o estado estacionário (provavelmente algumas amostras só)</strike>\n",
    "- [x] <strike> Quantos pontos mínimos para treinar bem ?</strike>\n",
    "- [ ] Gerar novo dataset com ordem 0, ver se outra função de ativação se adeua melhor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ef493-9f04-4d56-9dc8-12d4752cfecc",
   "metadata": {},
   "source": [
    "<H1>0. Import packages </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb28e0-e7c3-40b1-a0d0-bc75735809df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "history = History()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9b4d9-a768-4d7f-abc4-213d01a1ebb7",
   "metadata": {},
   "source": [
    "<h2>1. Read data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e611f2-d1ef-4863-bf0a-a97f3a1699d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data_section/datas/data_n1000_order2.csv'\n",
    "# data_path = '../data_section/datas/data_n1000_order2_adiabatic.csv'\n",
    "# data_path = '../data_section/datas/data_n1000_order0.csv'\n",
    "# data_path = '../data_section/datas/data_n100_order2.csv'\n",
    "# data_path = '../data_section/datas/data_n50_order2.csv'\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "outsample_data = pd.read_csv('../data_section/datas/outsample_test.csv', index_col=0)\n",
    "V = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a04d0-0e20-4071-afe0-ad933b94795a",
   "metadata": {},
   "source": [
    "<h2>2. Select features</h2>\n",
    "\n",
    "- Normalize it\n",
    "- Split it in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe09316-58d2-461f-9161-fc734551b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['Cae', 'Cbe', 'Te']\n",
    "y_col = ['Cc']\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "in_data = minmax.fit_transform(data[x_cols].to_numpy())\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(in_data, data[y_col].to_numpy(), test_size=.3, )\n",
    "Y_test = Y_test.reshape(Y_test.shape[0])\n",
    "Y_train = Y_train.reshape(Y_train.shape[0])\n",
    "\n",
    "print(f'x train: {X_train.shape}, x test: {X_test.shape}')\n",
    "print(f'y train: {Y_train.shape}, y test: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d2cdc-e95e-4c83-bdea-a84006d68182",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>3. Create the network </h2>\n",
    "\n",
    "- How many layers\n",
    "- How many neurons per layer\n",
    "- Which activation function\n",
    "- Which metrics\n",
    "- How long will be the training (using epochs)\n",
    "- Whether use validation sets or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d96ab-8da1-489f-9e77-038823ca00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(81, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(37, activation='exponential', ))\n",
    "model.add(Dense(15, activation='sigmoid', ))\n",
    "model.add(Dense(3, activation='exponential'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, epochs=200, verbose=0, validation_split=.3, use_multiprocessing=True,\n",
    "                 initial_epoch=50)\n",
    "evaluate(model, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd288ab-9eb2-4b4f-a279-815914f467aa",
   "metadata": {},
   "source": [
    "<h2>4. Validate the results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f2cc3-0cb4-44c7-90e1-93e69772b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c4782-ccf9-48db-b663-329feef0cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_identity_keras(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f792c-dc1f-4070-8a7a-be73959b5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rnn_keras(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e07489-703f-408a-975a-c08d0cf4158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_first_layer_keras(model, label=x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a3c2c-d096-4be8-afd1-b94fa4461725",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot_input(in_data, x_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53543109-6d20-421f-911e-5e111439cd28",
   "metadata": {},
   "source": [
    "<H2>5. Save the model</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf86538-b844-4154-990e-5312c95c322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/' + data_path.split('/')[-1].replace('data', 'model').replace('csv', 'h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc3927-cfd1-4b0c-b708-43c72985e5ef",
   "metadata": {},
   "source": [
    "<h2>6. (OPTIONAL) Load the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edec830-98cf-4e94-a8e7-37034e1cb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/model_n100_order2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898197f-4212-49c4-89aa-e24a157c1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_identity_keras(model, in_data, data['Cc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb646a69-df63-4b89-9842-e64851e761ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_outsample_data = outsample_data.copy()\n",
    "for col in x_cols:\n",
    "    _outsample_data = _outsample_data[(_outsample_data[col] > data[col].min()) & (_outsample_data[col] < data[col].max())]\n",
    "_outsample_data_y = _outsample_data['Cc']\n",
    "_outsample_data_x = minmax.fit_transform(_outsample_data[x_cols].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a15f63-9343-4de6-8ddd-a7eefad30ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_identity_keras(model, _outsample_data_x, _outsample_data_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_env",
   "language": "python",
   "name": "tcc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
